{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twelve way segmentation workbook\n",
    "- Takes an imput data volume and a 2D Unet trained for binary segmentation\n",
    "- Slices the data volume in the three orthogonal planes and predicts output for each slice\n",
    "- The predictions are recombined into 3D volumes and then summed\n",
    "- The input data volume is rotated by 90 degrees before the slicing and prediction steps are performed again\n",
    "- This is repeated until 4 rotations have been been performed\n",
    "- All the volumes are summed to give a prediction that is the sum of predictions in 12 different directions, a list of threshold values for a consensus cutoff is used to give a number of output volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import re\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import h5py as h5\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from skimage import img_as_ubyte, io, exposure, img_as_float\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Paths that are needed\n",
    "1. `root_path` - Root filepath for output directories, folder will be created\n",
    "2. `data_vol_path` - Path to the HDF5 volume to be segmented. Data should be in `/data` inside the file\n",
    "3. `learner_root_path` - Path to the folder containing the model file\n",
    "4. `learner_file` - Filename of the pickled 2d Unet model file. Needs to have been trained using BCE loss. For binary segmentation only\n",
    "5. `consensus_vals` - List of consensus cutoff values for agreement between volumes e.g. if 10 is in the list a volume will be output thresholded on consensus between 10 volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_data = Path(\"/dls/p45/data/2019/cm22981-2/processing/segmentation/win_data\")\n",
    "data_vol_path = win_data/'fullsize/200402_volume2/vol_750/vol2_750_z_stack_normalised.h5'\n",
    "root_path = win_data/'vol_2_9_way_prediction'\n",
    "learner_root_path = win_data\n",
    "learner_file = '200224_trainedUnet256_2.pkl'\n",
    "consensus_vals = [8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs = partial(os.makedirs, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_from_data(path):    \n",
    "    f = h5.File(path, 'r')\n",
    "    d = f['/data']\n",
    "    return da.from_array(d, chunks='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed because prediction doesn't work on odd sized images\n",
    "def fix_odd_sides(example_image):\n",
    "    if (list(example_image.size)[0] % 2) != 0:\n",
    "        example_image = crop_pad(example_image, \n",
    "                            size=(list(example_image.size)[0]+1, list(example_image.size)[1]),\n",
    "                            padding_mode = 'reflection')\n",
    "\n",
    "    if (list(example_image.size)[1] % 2) != 0:\n",
    "        example_image = crop_pad(example_image, \n",
    "                            size=(list(example_image.size)[0], list(example_image.size)[1] + 1),\n",
    "                            padding_mode = 'reflection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_slice(learn, axis, val, data, output_path):\n",
    "    #data = data.compute()\n",
    "    data = img_as_float(data)\n",
    "    img = Image(pil2tensor(data, dtype=np.float32))\n",
    "    fix_odd_sides(img)\n",
    "    prediction = learn.predict(img)\n",
    "    pred_slice = img_as_ubyte(prediction[1][0])\n",
    "    io.imsave(output_path/f\"unet_prediction_{axis}_stack_{val}.png\", pred_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_orthog_slices_to_disk(learn, axis, data_arr, output_path):\n",
    "    \"\"\"Outputs slices from data or ground truth seg volumes sliced in any or all three of the orthogonal planes\"\"\"\n",
    "    data_shape = data_arr.shape\n",
    "    name_prefix = 'seg'\n",
    "    # There has to be a cleverer way to do this!\n",
    "    if axis in ['z', 'all']:\n",
    "        print('Predicting z stack')\n",
    "        for val in range(data_shape[0]):\n",
    "            predict_single_slice(learn, 'z', val, data_arr[val, :, :], output_path)\n",
    "    if axis in ['x', 'all']:\n",
    "        print('Predicting x stack')\n",
    "        for val in range(data_shape[1]):\n",
    "            predict_single_slice(learn, 'x', val, data_arr[:, val, :], output_path)                    \n",
    "    if axis in ['y', 'all']:\n",
    "        print('Predicting y stack')\n",
    "        for val in range(data_shape[2]):\n",
    "            predict_single_slice(learn, 'y', val, data_arr[:, :, val], output_path)\n",
    "    if axis not in ['x', 'y', 'z', 'all']:\n",
    "        print(\"Axis should be one of: [all, x, y, or z]!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_folder_stucture(root_path):  \n",
    "    non_rotated = root_path/f'{date.today()}_non_rotated_seg_slices'\n",
    "    rot_90_seg = root_path/f'{date.today()}_rot_90_seg_slices'\n",
    "    rot_180_seg = root_path/f'{date.today()}_rot_180_seg_slices'\n",
    "    rot_270_seg = root_path/f'{date.today()}_rot_270_seg_slices'\n",
    "    \n",
    "    dir_list = [\n",
    "        ('non_rotated', non_rotated),\n",
    "        ('rot_90_seg', rot_90_seg),\n",
    "        ('rot_180_seg', rot_180_seg),\n",
    "        ('rot_270_seg', rot_270_seg)\n",
    "    ]\n",
    "    for key, dir_path in dir_list:\n",
    "        makedirs(dir_path)\n",
    "    return dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the loss in order to load the learner..\n",
    "def bce_loss(logits, labels):\n",
    "    logits=logits[:,1,:,:].float()\n",
    "    labels = labels.squeeze(1).float()\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "class BinaryLabelList(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn)\n",
    "\n",
    "class BinaryItemList(SegmentationItemList):\n",
    "    _label_cls = BinaryLabelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_slices_to_vol(folder_path):\n",
    "    output_path_list = []\n",
    "    file_list = folder_path.ls()\n",
    "    axis_list = ['z', 'x', 'y']\n",
    "    axis_regex = re.compile(r'\\_(\\D)\\_')\n",
    "    number_regex = re.compile(r'\\_(\\d+)\\.png')\n",
    "    for axis in axis_list:\n",
    "        axis_files = [x for x in file_list if re.search(f'\\_({axis})\\_', str(x))]\n",
    "        print(f\"Creating volume from {axis} stack\")\n",
    "        print(f'{len(axis_files)} files found')\n",
    "        first_im = open_image(axis_files[0])\n",
    "        shape_tuple = first_im.shape\n",
    "        if axis == 'z':\n",
    "            z_dim = len(axis_files)\n",
    "            x_dim = shape_tuple[1]\n",
    "            y_dim = shape_tuple[2]\n",
    "        elif axis == 'x':\n",
    "            z_dim = shape_tuple[1]\n",
    "            x_dim = len(axis_files)\n",
    "            y_dim = shape_tuple[2]\n",
    "        elif axis == 'y':\n",
    "            z_dim = shape_tuple[1]\n",
    "            x_dim = shape_tuple[2]\n",
    "            y_dim = len(axis_files)\n",
    "         \n",
    "        data_vol = np.empty([z_dim, x_dim, y_dim], dtype=np.uint8)\n",
    "        for filename in axis_files:\n",
    "            m = number_regex.search(str(filename))\n",
    "            pos = int(m.group(1))\n",
    "            im_data = io.imread(filename)\n",
    "            data_vol[pos, :, :] = im_data\n",
    "        if axis == 'x':\n",
    "            data_vol = np.swapaxes(data_vol, 0, 1)\n",
    "        if axis == 'y':\n",
    "            data_vol = np.swapaxes(data_vol, 0, 2)\n",
    "            data_vol = np.swapaxes(data_vol, 0, 1)\n",
    "        output_path = folder_path/f'{axis}_axis_seg_combined.h5'\n",
    "        output_path_list.append(output_path)\n",
    "        print(f'Outputting volume to {output_path}')\n",
    "        with h5.File(output_path, 'w') as f:\n",
    "            f['/data'] = data_vol\n",
    "    return output_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(input_path, range_list):\n",
    "    for val in range_list:\n",
    "        combined = da_from_data(input_path)\n",
    "        combined_out = input_path.parent/f'{date.today()}_combined_thresh_cutoff_{val}.h5'\n",
    "        combined[combined < val] = 0\n",
    "        combined[combined >= val] = 255\n",
    "        #combined = combined_da.compute()\n",
    "        print(f'Writing to {combined_out}')\n",
    "        combined.to_hdf5(combined_out, '/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a root directory for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data volume and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = da_from_data(data_vol_path)\n",
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(learner_root_path, learner_file)\n",
    "# Remove the restriction on the model prediction size\n",
    "learn.data.single_ds.tfmargs['size'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the loop to do repeated prediction and recombination steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to do this all in one go...\n",
    "axis = 'all'\n",
    "dir_list = setup_folder_stucture(root_path)\n",
    "combined_vol_paths = []\n",
    "data_arr = data_arr.compute()\n",
    "for k in range(4):\n",
    "    key, output_path = dir_list[k]\n",
    "    print(f'Key : {key}, output : {output_path}')\n",
    "    print(f'Rotating volume {k * 90} degrees')\n",
    "    rotated = np.rot90(data_arr, k)\n",
    "    predict_orthog_slices_to_disk(learn, axis, rotated, output_path)\n",
    "    output_path_list = combine_slices_to_vol(output_path)\n",
    "    fp = combine_vols(output_path_list, k, key)\n",
    "    combined_vol_paths.append(fp)\n",
    "# Combine all the volumes\n",
    "final_combined = combine_vols(combined_vol_paths, 0, 'final', True)\n",
    "threshold(final_combined, consensus_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

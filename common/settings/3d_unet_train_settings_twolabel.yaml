# Specify the location of the training and validation data
# Need a separate training and validation volume
data_dir: /home/vvw07985/k11_data/unet_dev/test_data
train_data: BINARY_stent_downsampled_384_DATA.h5
train_seg: BINARY_stent_downsampled_384_LABELS.h5
valid_data: BINARY_stent_downsampled_256_VALID_DATA.h5
valid_seg: BINARY_stent_downsampled_256_VALID_LABELS.h5
model_out_fn: 210225_3d_test_model_2_channel_multilabel.pytorch # Filename for the model output
# Parameters for finding learning rate
starting_lr: 1e-6 # Lower bound of learning rate search
end_lr: 10 # Upper Bound of learning rate search
lr_find_epochs: 1 # Number of training epochs for learning rate search
# Training parameters
num_epochs: 5 # Maximum number of epochs for training
patience: 2 # Number of epoch to wait before early stopping if validation loss does not improve
# Parameters for generating training patches
patch_size:
  [160, 160, 160]
train_patches: 48 # Number of patches to sample from the training volume
valid_patches: 12 # Number of patches to sample from the validation volume
max_queue_length: 48 # Maximum queue of pathches to create (the larger the number the more RAM required)
num_workers: 8 # Number of processor cores to use to generate patches

cuda_device: 3 # The graphics card to use (between 0 and 3 for a machine with 4 GPUs)
thresh_val: 0.5 # Threshold cutoff value for segmentation preview. Must be between 0 and 1.
# Parameters to control unet architecture
model:
  # model class, e.g. UNet3D, ResidualUNet3D
  name: ResidualUNet3D
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  #out_channels: 3 # multi-class
  # determines the order of operators in a single layer (gcr - GroupNorm+Conv3d+ReLU)
  layer_order: gcr
  # feature maps scale factor
  f_maps: 32
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: false
  # if True applies the final normalization layer (sigmoid or softmax), otherwise the networks
  # returns the output from the final convolution layer; use False for regression problems, e.g. de-noising
  is_segmentation: false

loss_criterion: DiceLoss # Choose from one of [BCEDiceLoss, BCELoss, DiceLoss, GeneralizedDiceLoss, CrossEntropyLoss]
alpha: 0.75 # When BCEDiceLoss selected, weighting for BCELoss
beta: 0.25 # When BCEDiceLoss selected, weighting for DiceLoss
eval_metric: MeanIoU # Choose from one of [MeanIoU, GenericAveragePrecision]
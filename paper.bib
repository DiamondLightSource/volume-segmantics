@article{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
	language = {en},
	number = {3},
	urldate = {2020-05-21},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	pages = {211--252},
	file = {Full Text:C\:\\Users\\vvw07985\\Zotero\\storage\\PW86KSMI\\Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf:application/pdf},
}

@inproceedings{perslev_one_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {One {Network} to {Segment} {Them} {All}: {A} {General}, {Lightweight} {System} for {Accurate} {3D} {Medical} {Image} {Segmentation}},
	isbn = {978-3-030-32245-8},
	shorttitle = {One {Network} to {Segment} {Them} {All}},
	doi = {10.1007/978-3-030-32245-8_4},
	abstract = {Many recent medical segmentation systems rely on powerful deep learning models to solve highly specific tasks. To maximize performance, it is standard practice to evaluate numerous pipelines with varying model topologies, optimization parameters, pre- \& postprocessing steps, and even model cascades. It is often not clear how the resulting pipeline transfers to different tasks.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2019},
	publisher = {Springer International Publishing},
	author = {Perslev, Mathias and Dam, Erik Bjørnager and Pai, Akshay and Igel, Christian},
	editor = {Shen, Dinggang and Liu, Tianming and Peters, Terry M. and Staib, Lawrence H. and Essert, Caroline and Zhou, Sean and Yap, Pew-Thian and Khan, Ali},
	year = {2019},
	pages = {30--38},
	file = {Submitted Version:C\:\\Users\\vvw07985\\Zotero\\storage\\ZHURWZB7\\Perslev et al. - 2019 - One Network to Segment Them All A General, Lightw.pdf:application/pdf},
}

@article{buslaev_albumentations_2020,
	title = {Albumentations: {Fast} and {Flexible} {Image} {Augmentations}},
	volume = {11},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/11/2/125},
	doi = {10.3390/info11020125},
	number = {2},
	journal = {Information},
	author = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},
	year = {2020},
}

@misc{alvarez-borges_u-net_2022,
	title = {U-{Net} {Segmentation} {Methods} for {Variable}-{Contrast} {XCT} {Images} of {Methane}-{Bearing} {Sand} {Using} {Small} {Training} {Datasets}},
	copyright = {Creative Commons Attribution 4.0 International License},
	url = {http://www.essoar.org/doi/10.1002/essoar.10506807.2},
	doi = {10.1002/essoar.10506807.2},
	abstract = {Methane (CH4) hydrate dissociation and CH4 release are potential geohazards currently investigated using X-ray computed tomography (XCT) imaging in laboratory experiments. Image segmentation constitu},
	language = {EN},
	urldate = {2022-07-25},
	publisher = {Earth and Space Science Open Archive},
	author = {Alvarez-Borges, Fernando Jesus and King, Oliver N. F. and Madhusudhan, B. N. and Connolley, Thomas and Basham, Mark and Ahmed, Sharif I.},
	month = jul,
	year = {2022},
	note = {Section: Soil Science},
}

@article{tun_massively_2021,
	title = {A massively multi-scale approach to characterizing tissue architecture by synchrotron micro-{CT} applied to the human placenta},
	volume = {18},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2021.0140},
	doi = {10.1098/rsif.2021.0140},
	abstract = {Multi-scale structural assessment of biological soft tissue is challenging but essential to gain insight into structure–function relationships of tissue/organ. Using the human placenta as an example, this study brings together sophisticated sample preparation protocols, advanced imaging and robust, validated machine-learning segmentation techniques to provide the first massively multi-scale and multi-domain information that enables detailed morphological and functional analyses of both maternal and fetal placental domains. Finally, we quantify the scale-dependent error in morphological metrics of heterogeneous placental tissue, estimating the minimal tissue scale needed in extracting meaningful biological data. The developed protocol is beneficial for high-throughput investigation of structure–function relationships in both normal and diseased placentas, allowing us to optimize therapeutic approaches for pathological pregnancies. In addition, the methodology presented is applicable in the characterization of tissue architecture and physiological behaviours of other complex organs with similarity to the placenta, where an exchange barrier possesses circulating vascular and avascular fluid spaces.},
	number = {179},
	urldate = {2022-07-21},
	journal = {Journal of The Royal Society Interface},
	author = {Tun, W. M. and Poologasundarampillai, G. and Bischof, H. and Nye, G. and King, O. N. F. and Basham, M. and Tokudome, Y. and Lewis, R. M. and Johnstone, E. D. and Brownbill, P. and Darrow, M. and Chernyavsky, I. L.},
	note = {Publisher: Royal Society},
	keywords = {computed tomography, contrast agent, flow network, human placenta, machine-learning segmentation, spatial statistics},
	pages = {20210140},
	file = {Full Text PDF:C\:\\Users\\vvw07985\\Zotero\\storage\\LCAP6DDP\\Tun et al. - A massively multi-scale approach to characterizing.pdf:application/pdf},
	month = jun,
	year = {2021},
}

@misc{Yakubovskiy:2019,
  author = {Pavel Yakubovskiy},
  title = {Segmentation Models Pytorch},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/qubvel/segmentation_models.pytorch}
}

@article{pennington_survos_2022,
	title = {{SuRVoS} 2: {Accelerating} {Annotation} and {Segmentation} for {Large} {Volumetric} {Bioimage} {Workflows} {Across} {Modalities} and {Scales}},
	volume = {10},
	issn = {2296-634X},
	url = {https://www.frontiersin.org/articles/10.3389/fcell.2022.842342},
	doi = {10.3389/fcell.2022.842342},
	abstract = {As sample preparation and imaging techniques have expanded and improved to include a variety of options for larger sized and numbers of samples, the bottleneck in volumetric imaging is now data analysis. Annotation and segmentation are both common, yet difficult, data analysis tasks which are required to bring meaning to the volumetric data. The SuRVoS application has been updated and redesigned to provide access to both manual and machine learning-based segmentation and annotation techniques, including support for crowd sourced data. Combining adjacent, similar voxels (supervoxels) provides a mechanism for speeding up segmentation both in the painting of annotation and by training a segmentation model on a small amount of annotation. The support for layers allows multiple datasets to be viewed and annotated together which, for example, enables the use of correlative data (e.g. crowd-sourced annotations or secondary imaging techniques) to guide segmentation. The ability to work with larger data on high-performance servers with GPUs has been added through a client-server architecture and the Pytorch-based image processing and segmentation server is flexible and extensible, and allows the implementation of deep learning-based segmentation modules. The client side has been built around Napari allowing integration of SuRVoS into an ecosystem for open-source image analysis while the server side has been built with cloud computing and extensibility through plugins in mind. Together these improvements to SuRVoS provide a platform for accelerating the annotation and segmentation of volumetric and correlative imaging data across modalities and scales.},
	journal = {Frontiers in Cell and Developmental Biology},
	author = {Pennington, Avery and King, Oliver N. F. and Tun, Win Min and Ho, Elaine M. L. and Luengo, Imanol and Darrow, Michele C. and Basham, Mark},
	year = {2022},
}

# Specify the location of the training and validation data
# Need a separate training and validation volume
data_dir: /dls/k11/data/2020/cm26457-3/processing/olly/gas_hydrates/200710_unet_segmentation/datafiles 
train_data: 89069_centre_384_data_uint8.h5
train_seg: 89069_centre_384_seg_uint8_lbl_fixed.h5  # Need to ensure values are [0,1]
valid_data: 89069_validation_384_data_uint8.h5
valid_seg: 89069_validation_384_seg_uint8_lbl_fixed.h5  # Need to ensure values are [0,1]
model_out_fn: 200725_3dUnet_sand_brine_meth_multilabel_3cDL_p30.pytorch # Filename for the model output
# Parameters for finding learning rate
starting_lr: 1e-6 # Lower bound of learning rate search
end_lr: 20 # Upper Bound of learning rate search
lr_find_epochs: 1 # Number of training epochs for learning rate search
# Training parameters
num_epochs: 100 # Maximum number of epochs for training
patience: 30 # Number of epoch to wait before early stopping if validation loss does not improve
# Parameters for generating training patches
patch_size:
  [128, 128, 128]
train_patches: 48 # Number of patches to sample from the training volume
valid_patches: 12 # Number of patches to sample from the validation volume
max_queue_length: 48 # Maximum queue of pathches to create (the larger the number the more RAM required)
num_workers: 8 # Number of processor cores to use to generate patches

cuda_device: 1 # The graphics card to use (between 0 and 3 for a machine with 4 GPUs)
thresh_val: 0.5 # Threshold cutoff value for segmentation preview. Must be between 0 and 1.
# Parameters to control unet architecture
model:
  # model class, e.g. UNet3D, ResidualUNet3D
  name: ResidualUNet3D
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 3 # multi-class
  # determines the order of operators in a single layer (gcr - GroupNorm+Conv3d+ReLU)
  layer_order: gcr
  # feature maps scale factor
  f_maps: 32
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: false
  # if True applies the final normalization layer (sigmoid or softmax), otherwise the networks
  # returns the output from the final convolution layer; use False for regression problems, e.g. de-noising
  is_segmentation: true

loss_criterion: DiceLoss # Choose from one of [BCEDiceLoss, BCELoss, DiceLoss, GeneralizedDiceLoss, CrossEntropyLoss]
alpha: 0.75 # When BCEDiceLoss selected, weighting for BCELoss
beta: 0.25 # When BCEDiceLoss selected, weighting for DiceLoss
eval_metric: MeanIoU # Choose from one of [MeanIoU, GenericAveragePrecision]